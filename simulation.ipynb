{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information Estimation Quality\n",
    "\n",
    "In this experiment, we compare our CLUB estimator with other baselines on MI estimation quality. \n",
    "First, we draw samples from Gaussian and Cubic distributions with the true MI values pre-known. Then we compare different MI estimators on estimating MI values based on the generated samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the sampling function, which can sample Gaussian or Cubic data with the given [correlation coefficient](https://en.wikipedia.org/wiki/Correlation_and_dependence) $\\rho$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_correlated_gaussian(rho=0.5, dim=20, batch_size=128, to_cuda=False,cubic=None):\n",
    "    \"\"\"Generate samples from a correlated Gaussian distribution.\"\"\"\n",
    "    mean = [0,0]\n",
    "    cov = [[1.0, rho],[rho, 1.0]]\n",
    "    x, y = np.random.multivariate_normal(mean, cov, batch_size * dim).T\n",
    "\n",
    "    x = x.reshape(-1, dim)\n",
    "    y = y.reshape(-1, dim)\n",
    "\n",
    "    if cubic is not None:\n",
    "        y = y ** 3\n",
    "\n",
    "    if to_cuda:\n",
    "        x = torch.from_numpy(x).float().cuda()\n",
    "        #x = torch.cat([x, torch.randn_like(x).cuda() * 0.3], dim=-1)\n",
    "        y = torch.from_numpy(y).float().cuda()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the Gaussian distribution, the correlation coefficient and mutual information have one-to-one mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_to_mi(rho, dim):\n",
    "    result = -dim / 2 * np.log(1 - rho **2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def mi_to_rho(mi, dim):\n",
    "    result = np.sqrt(1 - np.exp(-2 * mi / dim))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dim = 20\n",
    "batch_size = 64\n",
    "hidden_size = 15\n",
    "learning_rate = 0.005\n",
    "training_steps = 4000\n",
    "\n",
    "cubic = False\n",
    "model_list = [\"NWJ\", \"MINE\", \"InfoNCE\",\"L1OutUB\",\"CLUB\",\"CLUBSample\"]\n",
    "#model_list = [ \"MINE\",\"CLUBSample\"]\n",
    "\n",
    "mi_list = [2.0, 4.0, 6.0, 8.0, 10.0]\n",
    "\n",
    "total_steps = training_steps*len(mi_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train different MI estimators with samples drawn from different Gaussian or Cubic distributions with different MI true values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish training for NWJ with true MI value = 2.000000\n",
      "finish training for NWJ with true MI value = 4.000000\n",
      "finish training for NWJ with true MI value = 6.000000\n",
      "finish training for NWJ with true MI value = 8.000000\n",
      "finish training for NWJ with true MI value = 10.000000\n",
      "model NWJ average time cost is 0.003926 s\n",
      "finish training for MINE with true MI value = 2.000000\n",
      "finish training for MINE with true MI value = 4.000000\n",
      "finish training for MINE with true MI value = 6.000000\n",
      "finish training for MINE with true MI value = 8.000000\n",
      "finish training for MINE with true MI value = 10.000000\n",
      "model MINE average time cost is 0.003322 s\n",
      "finish training for InfoNCE with true MI value = 2.000000\n",
      "finish training for InfoNCE with true MI value = 4.000000\n",
      "finish training for InfoNCE with true MI value = 6.000000\n",
      "finish training for InfoNCE with true MI value = 8.000000\n",
      "finish training for InfoNCE with true MI value = 10.000000\n",
      "model InfoNCE average time cost is 0.003751 s\n",
      "finish training for L1OutUB with true MI value = 2.000000\n",
      "finish training for L1OutUB with true MI value = 4.000000\n",
      "finish training for L1OutUB with true MI value = 6.000000\n",
      "finish training for L1OutUB with true MI value = 8.000000\n",
      "finish training for L1OutUB with true MI value = 10.000000\n",
      "model L1OutUB average time cost is 0.004315 s\n",
      "finish training for CLUB with true MI value = 2.000000\n",
      "finish training for CLUB with true MI value = 4.000000\n",
      "finish training for CLUB with true MI value = 6.000000\n",
      "finish training for CLUB with true MI value = 8.000000\n",
      "finish training for CLUB with true MI value = 10.000000\n",
      "model CLUB average time cost is 0.004235 s\n",
      "finish training for CLUBSample with true MI value = 2.000000\n",
      "finish training for CLUBSample with true MI value = 4.000000\n",
      "finish training for CLUBSample with true MI value = 6.000000\n"
     ]
    }
   ],
   "source": [
    "# train MI estimators with samples \n",
    "from mi_estimators import *\n",
    "\n",
    "mi_results = dict()\n",
    "for i, model_name in enumerate(model_list):\n",
    "    \n",
    "    model = eval(model_name)(sample_dim, sample_dim, hidden_size).cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "    mi_est_values = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i, mi_value in enumerate(mi_list):\n",
    "        rho = mi_to_rho(mi_value, sample_dim)\n",
    "\n",
    "        for step in range(training_steps):\n",
    "            batch_x, batch_y = sample_correlated_gaussian(rho, dim=sample_dim, batch_size = batch_size, to_cuda = True, cubic = cubic)\n",
    "\n",
    "            model.eval()\n",
    "            mi_est_values.append(model.mi_est(batch_x, batch_y).item())\n",
    "            \n",
    "            model.train() \n",
    "            if model_name in [\"MINE\", \"InfoNCE\",\"NWJ\"]:\n",
    "                model_loss = - model.mi_est(batch_x, batch_y)\n",
    "            elif model_name in [\"CLUB\",\"CLUBSample\",\"L1OutUB\",\"VarUB\"]:\n",
    "                model_loss = - model.loglikeli(batch_x, batch_y)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            model_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            del batch_x, batch_y\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"finish training for %s with true MI value = %f\" % (model.__class__.__name__, mi_value))\n",
    "        # torch.save(model.state_dict(), \"./model/%s_%d.pt\" % (model.__class__.__name__, int(mi_value)))\n",
    "        torch.cuda.empty_cache()\n",
    "    end_time = time.time()\n",
    "    time_cost = end_time - start_time\n",
    "    print(\"model %s average time cost is %f s\" % (model_name, time_cost/total_steps))\n",
    "    mi_results[model_name] = mi_est_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "colors = sns.color_palette()\n",
    "\n",
    "EMA_SPAN = 200\n",
    "\n",
    "ncols = len(model_list)\n",
    "nrows = 1\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(3.1 *ncols , 3.4 * nrows))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "\n",
    "xaxis = np.array(list(range(total_steps)))\n",
    "yaxis_mi = np.repeat(mi_list, training_steps)\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    plt.sca(axs[i])\n",
    "    p1 = plt.plot(mi_results[model_name], alpha=0.4, color=colors[0])[0]  #color = 5 or 0\n",
    "    mis_smooth = pd.Series(mi_results[model_name]).ewm(span=EMA_SPAN).mean()\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.plot(mis_smooth, c=p1.get_color(), label='Estimated MI')\n",
    "        plt.plot(yaxis_mi, color='k', label='True MI')\n",
    "        plt.xlabel('Steps', fontsize= 14)\n",
    "        plt.ylabel('Mutual Information', fontsize = 14)\n",
    "        plt.legend(loc='upper left', prop={'size':15})\n",
    "    else:\n",
    "        plt.plot(mis_smooth, c=p1.get_color())\n",
    "        plt.yticks([])\n",
    "        plt.plot(yaxis_mi, color='k')\n",
    "        plt.xticks([])\n",
    "    \n",
    "    plt.ylim(0, 15.5)\n",
    "    plt.xlim(0, total_steps)   \n",
    "    plt.title(model_name, fontsize=15)\n",
    "    #plt.subplots_adjust( )\n",
    "\n",
    "plt.gcf().tight_layout()\n",
    "#plt.savefig(f'mi_gauss_py.pdf', bbox_inches=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the bias, variance and mean-squared-error (MSE) of the estimated MI to the true MI values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_dict = dict()\n",
    "var_dict = dict()\n",
    "mse_dict = dict()\n",
    "for i, model_name in enumerate(model_list):\n",
    "    bias_list = []\n",
    "    var_list = []\n",
    "    mse_list = []\n",
    "    for j in range(len(mi_list)):\n",
    "        mi_est_values = mi_results[model_name][training_steps*(j+1)- 500:training_steps*(j+1)]\n",
    "        est_mean = np.mean(mi_est_values)\n",
    "        bias_list.append(np.abs(mi_list[j] - est_mean))\n",
    "        var_list.append(np.var(mi_est_values))\n",
    "        mse_list.append(bias_list[j]**2+ var_list[j])\n",
    "    bias_dict[model_name] = bias_list\n",
    "    var_dict[model_name] = var_list\n",
    "    mse_dict[model_name] = mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')#('seaborn-notebook')\n",
    "\n",
    "colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "col_idx = [2,4,5,1,3,0]\n",
    "\n",
    "ncols = 1\n",
    "nrows = 3\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(4.5 * ncols, 3. * nrows))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for i, model_name in enumerate(model_list):\n",
    "    plt.sca(axs[0])\n",
    "    plt.plot(mi_list, bias_dict[model_name], label=model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "    \n",
    "    plt.sca(axs[1])\n",
    "    plt.plot(mi_list, var_dict[model_name], label=model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "    \n",
    "    plt.sca(axs[2])\n",
    "    plt.plot(mi_list, mse_dict[model_name], label=model_name, marker='d', color = colors[col_idx[i]][\"color\"]) \n",
    "        \n",
    "ylabels = ['Bias', 'Variance', 'MSE']\n",
    "for i in range(3):\n",
    "    plt.sca(axs[i])\n",
    "    plt.ylabel(ylabels[i], fontsize=15)\n",
    "    \n",
    "    if i == 0:\n",
    "        if cubic:\n",
    "            plt.title('Cubic', fontsize=17)\n",
    "        else:\n",
    "            plt.title('Gaussian', fontsize=17)\n",
    "    if i == 1:\n",
    "        plt.yscale('log')\n",
    "    if i == 2:\n",
    "        plt.legend(loc='upper left', prop={'size': 12})\n",
    "        plt.xlabel('MI Values',fontsize=15)\n",
    "        \n",
    "plt.gcf().tight_layout()\n",
    "#plt.savefig(f'bias_variance_cubic_py3.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
